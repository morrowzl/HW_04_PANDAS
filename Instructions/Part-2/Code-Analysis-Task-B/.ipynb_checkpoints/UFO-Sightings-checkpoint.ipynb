{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO Sightings\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: The cell below imports `pandas` as a dependency because `pandas` functions will be used throughout the program, such as the Pandas `DataFrame` as well as the `read_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line assigns a string to variable \"csv_path\". The string points to the location of a file on the hard drive.\n",
    "Line 3: \n",
    "Line instructs Python to create a dataframe called \"ufo_df\" using pandas' read_csv function to \"read\" the file located at the location specified by \"csv_path\" and interpret the contents.\n",
    "Line 5:\n",
    "Line displays the first (default since no other amount specified in parentheses) five rows of the dataframe \"ufo_df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"Resources/ufoSightings.csv\"\n",
    "\n",
    "ufo_df = pd.read_csv(csv_path)\n",
    "\n",
    "ufo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line instructs Python to count how many non-null entries are in each column of the \"ufo_df\" dataframe. Returns a series of column labels and corresponding entry counts (numeric).\n",
    "\n",
    "This is helpful for quickly checking the completeness of the data. If there are appreciable amounts of data missing, exluding it from further analyses could improve workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line1:\n",
    "Line defines \"clean_ufo_df\" to refer to a more specific state or form of \"ufo_df\", which excludes rows/columns that contain missing values, according to the how. Since how=\"any\", rows and columns that have any number of missing values will be excluded.\n",
    "\n",
    "Any:\n",
    "For how=\"any\" rows/columns will be dropped if a single value is missing. The benefit to using \"any\" is that the cleaned dataset will not contain nulls, which could allow for simpler/easier analysis and nicer looking vizualizations. The drawback to using \"any\" is that the size of the dataset could be drastically reduced, or the data could become much less representative of the intended sample population. \n",
    "\n",
    "All:\n",
    "For how=\"all\" rows/columns will be dropped if all the values in the row or column are missing. The benefit to using \"all\" is that more data would remain in the dataset, which could still be valuable to analysis. This would be the case especially if the missing values were not very important to begin with. The drawback to using all is that any calculations including existing values from the range could be less accurate relative to other ranges without missing values. \n",
    "\n",
    "Line 2:\n",
    "Line instructs Python to count how many non-null entries are in each column of the \"ufo_df\" dataframe. Returns a series of column labels and corresponding entry counts (numeric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ufo_df = ufo_df.dropna(how=\"any\")\n",
    "clean_ufo_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line creates new list \"columns\", which contains the listed strings, to be referenced later by \"loc\". The list \"columns\" will be used by \"loc\" to specify which columns to retain.\n",
    "\n",
    "Line 2:\n",
    "Line defines \"usa_ufo_df\" to refer to a specific state or form of \"clean_ufo_df\", whose contents are specified by the \"loc\" function. \"loc\" accepts label inputs for the desired rows and columns. The first input specifies that only rows whose values in the \"country\" column are equivalent to \"us\" should be included in \"usa_ufo_df\". The second input specifies that only columns whose labels are in the list \"columns\" should be included in \"usa_ufo_df.\n",
    "\n",
    "Line 13:\n",
    "Line displays the first (default since no other amount specified in parentheses) five rows of the filtered dataset \"usa_ufo_df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"datetime\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"country\",\n",
    "    \"shape\",\n",
    "    \"duration (seconds)\",\n",
    "    \"duration (hours/min)\",\n",
    "    \"comments\",\n",
    "    \"date posted\"\n",
    "]\n",
    "\n",
    "usa_ufo_df = clean_ufo_df.loc[clean_ufo_df[\"country\"] == \"us\", columns]\n",
    "usa_ufo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line defines \"state_counts\" to be the output of value_counts, which  will count the instances of each unique entry value that occurs in the specified \"state\" column of \"usa_ufo_df\". Returns series of unique values and their corresponding instance counts (numeric).\n",
    "\n",
    "Line 2: \n",
    "Line calls for the \"state_counts\" series to be displayed on the screen.\n",
    "\n",
    "The utility of these steps is that a summary of the range data can quickly be obtained and reviewed; Potential skews, outliers, etc. can be intermediately identified. Additionally, the value_counts output series can be stored as a variable and easily referenced later in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = usa_ufo_df[\"state\"].value_counts()\n",
    "state_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line instructs Python to create dataframe called \"state_ufo_counts_df\" using pandas' DataFrame function, which accesses the data stored as \"state_counts\" variable. The utility of \"passing\" the data as a dataframe is additional functionality/operation that the dataframe object (series) doesn't have. Examples of this utility are necessary for the following steps in which column labels are renamed to be more descriptive, and the data can be manipulated similarly to or presented alongside other dataframe entries.\n",
    "\n",
    "Line 2:\n",
    "Line displays the first five rows of the dataset \"state_ufo_counts_df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ufo_counts_df = pd.DataFrame(state_counts)\n",
    "state_ufo_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line passes a dict object to the columns parameter of the rename function, which changes the existing column label (specified by the dict's key) to the the new label (specified by the dict's value). This is more user-friendly because the previous label \"state\" was heading a column of integers (because the contents of the state column were used as the index when the new dataframe was created), which are actually the number of sightings in each state.\n",
    "\n",
    "Line 3:\n",
    "Line displays the first five rows of the dataframe under the new column label \"Sum of Sightings\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ufo_counts_df = state_ufo_counts_df.rename(\n",
    "    columns={\"state\": \"Sum of Sightings\"})\n",
    "state_ufo_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line calls the dtypes property which displays the dataframe's column labels along with their datatype (based on the consituent entry values). It's helpful to know the columns' datatypes so additional steps can be planned and executed based on the actions (manpulations, interactions) specific to or prohibited by the corresponding datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_ufo_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 1:\n",
    "Line uses loc function to specify the entries for all rows in the \"duration (seconds)\" column of usa_ufo_df, whose datatype is then passed as type \"float\". By changing the datatype to be numeric, arithmetic operations can be performed on the values.\n",
    "\n",
    "Line 2:\n",
    "Line calls the dtypes property which displays the dataframe's column labels along with their datatype (based on the consituent entry values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_ufo_df.loc[:, \"duration (seconds)\"] = usa_ufo_df[\"duration (seconds)\"].astype(\"float\")\n",
    "usa_ufo_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. What is the output and how were we able to accomplish this?]_\n",
    "Line 2:\n",
    "Line instructs Python to sum all the float values in the \"duration (seconds)\" column, which can be performed because we changed the datatype from object to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it is possible to find the sum of seconds\n",
    "usa_ufo_df[\"duration (seconds)\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. How did we group by two columns, and what are we now able to do as a result? Lastly, explain what does this output tell you.]_\n",
    "Line 1:\n",
    "Line defines \"grouped_data\" as a specific form of usa_ufo_df which organizes the dataset so entries are grouped by \"state\" and grouped further by \"city\". By doing so, if no other columns contain duplicate entries, we can count the number of unique entries to determine how many ufo sights have occurred in each city.\n",
    "\n",
    "Line 4:\n",
    "Line instructs Python to count the number of unique \"datetime\" entries, each of which represents a different ufo sighting. The output presents how many ufo sightings have occurred in each city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = usa_ufo_df.groupby(['state', 'city'])\n",
    "\n",
    "# Hint: If you are counting records, you can use any column and get the same result. Try it.\n",
    "grouped_data['datetime'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
